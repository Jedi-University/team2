{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9124932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/02 09:32:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa019ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[624, 365, 670, 687, 328]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fd5dc26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "|Gender| Name|Salary|\n",
      "+------+-----+------+\n",
      "|  Male|Vasia|  1000|\n",
      "|  Male|Peria|   500|\n",
      "|Famale|Sveta|   200|\n",
      "+------+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Gender: string, Name: string, Salary: bigint]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "rdd = sc.parallelize([\n",
    "    {\"Name\": \"Vasia\", \"Salary\": 1000, \"Gender\": \"Male\"},\n",
    "    {\"Name\": \"Peria\", \"Salary\": 500, \"Gender\": \"Male\"},\n",
    "    {\"Name\": \"Sveta\", \"Salary\": 200, \"Gender\": \"Famale\"}\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.createDataFrame(rdd)\n",
    "df.show()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d227ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "|  1000|\n",
      "|   500|\n",
      "|   200|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e137e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "|Gender| Name|Salary|\n",
      "+------+-----+------+\n",
      "|  Male|Vasia|  1000|\n",
      "+------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Name\") == \"Vasia\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51ab3526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "|  1000|\n",
      "|   200|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Name == 'Vasia' or Name = 'Sveta'\").select(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d05b40cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- avatar_url: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- events_url: string (nullable = true)\n",
      " |-- hooks_url: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- issues_url: string (nullable = true)\n",
      " |-- login: string (nullable = true)\n",
      " |-- members_url: string (nullable = true)\n",
      " |-- node_id: string (nullable = true)\n",
      " |-- public_members_url: string (nullable = true)\n",
      " |-- repos_url: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orgs_df = spark.read.option(\"multiline\",\"true\").json(\"github.json\")\n",
    "orgs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9458bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          avatar_url|         description|          events_url|           hooks_url|  id|          issues_url|            login|         members_url|             node_id|  public_members_url|           repos_url|                 url|\n",
      "+--------------------+--------------------+--------------------+--------------------+----+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...|  44|https://api.githu...|          errfree|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...|  81|https://api.githu...|       engineyard|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 119|https://api.githu...| ministrycentered|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|We build software...|https://api.githu...|https://api.githu...| 128|https://api.githu...|   collectiveidea|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 144|https://api.githu...|              ogc|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 150|https://api.githu...|        sevenwire|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 167|https://api.githu...|         entryway|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 264|https://api.githu...|             merb|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 359|https://api.githu...|      moneyspyder|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 374|https://api.githu...|         sproutit|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 489|https://api.githu...|       wrenchlabs|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 555|https://api.githu...|ipvideomarketinfo|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                    |https://api.githu...|https://api.githu...| 728|https://api.githu...|       revelation|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|We're an agile te...|https://api.githu...|https://api.githu...|1067|https://api.githu...|        railslove|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|Leading Spree Com...|https://api.githu...|https://api.githu...|1119|https://api.githu...|         railsdog|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                   7|https://api.githu...|https://api.githu...|1146|https://api.githu...|          netguru|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                   6|https://api.githu...|https://api.githu...|1190|https://api.githu...|         animikii|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                   5|https://api.githu...|https://api.githu...|1375|https://api.githu...|              cdr|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                   5|https://api.githu...|https://api.githu...|1511|https://api.githu...|         sauspiel|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "|https://avatars.g...|                   4|https://api.githu...|https://api.githu...|1849|https://api.githu...|       wherecloud|https://api.githu...|MDEyOk9yZ2FuaXphd...|https://api.githu...|https://api.githu...|https://api.githu...|\n",
      "+--------------------+--------------------+--------------------+--------------------+----+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orgs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cea55cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           repos_url|\n",
      "+--------------------+\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "|https://api.githu...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orgs_df.select(\"repos_url\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b8796e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         description|count|\n",
      "+--------------------+-----+\n",
      "|                   7|    1|\n",
      "|                   3|    2|\n",
      "|We build software...|    1|\n",
      "|                   5|    2|\n",
      "|                   6|    1|\n",
      "|Leading Spree Com...|    1|\n",
      "|We're an agile te...|    1|\n",
      "|                   1|    3|\n",
      "|                   4|    2|\n",
      "|                    |   12|\n",
      "|                  4.|    1|\n",
      "|                   2|    3|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orgs_df.groupBy(\"description\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8e65f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-----+\n",
      "|Gender| Name|Salary|Upper|\n",
      "+------+-----+------+-----+\n",
      "|  Male|Vasia|  1000|VASIA|\n",
      "|  Male|Peria|   500|PERIA|\n",
      "|Famale|Sveta|   200|SVETA|\n",
      "+------+-----+------+-----+\n",
      "\n",
      "+------+-----+------+--------------+\n",
      "|Gender| Name|Salary|Inversion Name|\n",
      "+------+-----+------+--------------+\n",
      "|  Male|Vasia|  1000|         aisaV|\n",
      "|  Male|Peria|   500|         aireP|\n",
      "|Famale|Sveta|   200|         atevS|\n",
      "+------+-----+------+--------------+\n",
      "\n",
      "+------+-----+------+------------------+\n",
      "|Gender| Name|Salary|Salary after taxes|\n",
      "+------+-----+------+------------------+\n",
      "|  Male|Vasia|  1000|             870.0|\n",
      "|  Male|Peria|   500|             435.0|\n",
      "|Famale|Sveta|   200|             174.0|\n",
      "+------+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "\n",
    "\n",
    "@udf(returnType=StringType()) \n",
    "def uppercase(value: str):\n",
    "    return value.upper()\n",
    "\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def inversion(value: str):\n",
    "    return value[::-1]\n",
    "\n",
    "\n",
    "@udf(returnType=FloatType())\n",
    "def calculation_of_taxes(value: float, percent: float):\n",
    "    return value - (value * percent) / 100 \n",
    "    \n",
    "\n",
    "df.withColumn(\"Upper\", uppercase(col(\"Name\"))).show()\n",
    "df.withColumn(\"Inversion Name\", inversion(col(\"Name\"))).show()\n",
    "df.withColumn(\"Salary after taxes\", calculation_of_taxes(col(\"Salary\"), lit(13))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0d9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
